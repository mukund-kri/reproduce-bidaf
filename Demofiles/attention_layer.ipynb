{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combination = '1,2,1*2,1*3'\n",
    "combinations = combination.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_layer(matrix_1,matrix_2):\n",
    "        matrix_1 = keras.utils.normalize(matrix_1)\n",
    "        matrix_2 = keras.utils.normalize(matrix_2)\n",
    "        num_rows_1 = K.shape(matrix_1)[1]   #no_of_words_in_passage\n",
    "        num_rows_2 = K.shape(matrix_2)[1]   #no_of_words_in_query\n",
    "        tile_dims_1 = K.concatenate([[1, 1], [num_rows_2], [1]], 0)    #concatenate size of h and u for making it as a same size\n",
    "        tile_dims_2 = K.concatenate([[1], [num_rows_1], [1, 1]], 0)\n",
    "        tiled_matrix_1 = K.tile(K.expand_dims(matrix_1, axis=2), tile_dims_1)\n",
    "        tiled_matrix_2 = K.tile(K.expand_dims(matrix_2, axis=1), tile_dims_2)\n",
    "        cos_sim = K.sum(tiled_matrix_1 * tiled_matrix_2,axis = -1)  #Finds the similarity of h and u\n",
    "        #Context to query\n",
    "        atj = K.softmax(cos_sim) #attention vector\n",
    "        matrix_2 = tf.constant(matrix_2)\n",
    "        num_attention_dims = K.ndim(atj)      \n",
    "        num_matrix_dims = K.ndim(matrix_2) - 1\n",
    "        for _ in range(num_attention_dims - num_matrix_dims):\n",
    "            matrix_2 = K.expand_dims(matrix_2, axis=1)   #making the dimension of atj and matrix_2 same\n",
    "        u_aug = K.sum(K.expand_dims(atj, axis=-1) * matrix_2, -2)    #finding U_Aug\n",
    "        #Query to Context\n",
    "        question_passage_similarity = K.max(cos_sim, axis=-1)\n",
    "        btj = K.softmax(question_passage_similarity)  #Attention Vector\n",
    "        matrix_1 = tf.constant(matrix_1)\n",
    "        num_attention_dims2 = K.ndim(btj)\n",
    "        num_matrix_dims2 = K.ndim(matrix_1) - 1\n",
    "        for _ in range(num_attention_dims2 - num_matrix_dims2):\n",
    "            matrix_1 = K.expand_dims(matrix_1, axis=1)\n",
    "        h_aug =  K.sum(K.expand_dims(btj, axis=-1) * matrix_1, -2)\n",
    "        h_aug_final = find_h_aug(h_aug = h_aug,matrix= matrix_1)   #finding H_Aug\n",
    "        final_pass = final_passage([matrix_1,u_aug,h_aug_final])   #finding G\n",
    "        return final_pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_h_aug(h_aug,matrix):\n",
    "    to_repeat = h_aug\n",
    "    to_copy = matrix\n",
    "    expanded = K.expand_dims(to_repeat, axis=1)\n",
    "    ones = [1] * K.ndim(expanded)\n",
    "    num_repetitions = K.shape(to_copy)[1]\n",
    "    tile_shape = K.concatenate([ones[:1], [num_repetitions], ones[2:]], 0)\n",
    "    h_aug_final = K.tile(expanded,tile_shape)\n",
    "    return h_aug_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_combination(combination: str, tensors: List['Tensor']):\n",
    "        if combination.isdigit():\n",
    "            return tensors[int(combination) - 1]  # indices in the combination string are 1-indexed\n",
    "        else:\n",
    "            first_tensor = _get_combination(combination[0], tensors)\n",
    "            second_tensor = _get_combination(combination[2], tensors)\n",
    "            if K.int_shape(first_tensor) != K.int_shape(second_tensor):\n",
    "                shapes_message = \"Shapes were: {} and {}\".format(K.int_shape(first_tensor),\n",
    "                                                                 K.int_shape(second_tensor))\n",
    "              \n",
    "            operation = combination[1]\n",
    "            if operation == '*':\n",
    "                return first_tensor * second_tensor\n",
    "            elif operation == '/':\n",
    "                return first_tensor / second_tensor\n",
    "            elif operation == '+':\n",
    "                return first_tensor + second_tensor\n",
    "            elif operation == '-':\n",
    "                return first_tensor - second_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_passage(x):\n",
    "        combined_tensor = _get_combination(combinations[0], x)\n",
    "        for combination in combinations[1:]:\n",
    "            to_concatenate = _get_combination(combination, x)\n",
    "            combined_tensor = K.concatenate([combined_tensor, to_concatenate], axis=-1)\n",
    "        return combined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_24:0' shape=(1, 866, 2048) dtype=float64>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = attention_layer(matrix_1,matrix_2)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
