{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Embedding, add, dot, Input, Activation\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context train read\n",
      "Query train read\n",
      "shared  read\n"
     ]
    }
   ],
   "source": [
    "context_train = json.load(open('data/squad/context_train_useful.json'))\n",
    "print('Context train read')\n",
    "query_train = json.load(open('data/squad/query_train.json'))\n",
    "print('Query train read')\n",
    "shared = json.load(open('data/squad/shared.json'))\n",
    "print('shared  read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_emb_size = 100\n",
    "num_classes = T = len(context_train['context_idx'][0])\n",
    "J = len(query_train['question_idx'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_start, y_train_end = [], [] \n",
    "for x, y in zip(query_train['answer_start'], query_train['answer_end']):\n",
    "    y_train_start.append(x[0])\n",
    "    y_train_end.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_start_encoded = to_categorical(y_train_start, num_classes)\n",
    "y_train_end_encoded = to_categorical(y_train_end, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_mat = np.array([shared['word2vec'][word] if word in shared['word2vec']\n",
    "                        else np.random.multivariate_normal(np.zeros(word_emb_size), np.eye(word_emb_size))\n",
    "                        for word in shared['all_words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1_input = Input(shape = (T,))\n",
    "model1_embed = Embedding(output_dim=100, input_dim=emb_mat.shape[0], weights = [emb_mat], trainable = False)(model1_input)\n",
    "model1_lstm = Bidirectional(LSTM(256, return_sequences = True))(model1_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2_input = Input(shape = (J, ))\n",
    "model2_embed = Embedding(output_dim=100, input_dim=emb_mat.shape[0], weights = [emb_mat], trainable = False)(model2_input)\n",
    "model2_lstm = Bidirectional(LSTM(256, return_sequences = True))(model2_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiply_layer = dot([model1_lstm, model2_lstm],axes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelling_bilstm_layer = Bidirectional(LSTM(256, return_sequences = True))(multiply_layer)\n",
    "modelling_bilstm_layer_1 = Bidirectional(LSTM(256))(modelling_bilstm_layer)\n",
    "modelling_bilstm_layer_return_sequences = Bidirectional(LSTM(256, return_sequences = True))(modelling_bilstm_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_start_index = Dense(num_classes,activation='softmax')(modelling_bilstm_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_end_index_lstm = LSTM(num_classes)(modelling_bilstm_layer_return_sequences)\n",
    "merge = add([output_end_index_lstm,output_start_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_end_index_lstm = Activation('softmax')(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = Model(inputs=[model1_input, model2_input], outputs=[output_start_index, output_end_index_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 866)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 60)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 866, 100)      9596200     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 60, 100)       9596200     input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional)  (None, 866, 512)      731136      embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional)  (None, 60, 512)       731136      embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dot_6 (Dot)                      (None, 866, 60)       0           bidirectional_7[0][0]            \n",
      "                                                                   bidirectional_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional)  (None, 866, 512)      649216      dot_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional) (None, 512)           1574912     bidirectional_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional) (None, 866, 512)      1574912     bidirectional_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 866)           444258      bidirectional_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                   (None, 866)           4776856     bidirectional_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 866)           0           lstm_12[0][0]                    \n",
      "                                                                   dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 866)           0           add_1[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 29,674,826\n",
      "Trainable params: 10,482,426\n",
      "Non-trainable params: 19,192,400\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
